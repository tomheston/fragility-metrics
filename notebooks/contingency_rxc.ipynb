{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4bla5wCcRRmwtJP2dVOk8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomheston/fragility-metrics/blob/main/notebooks/contingency_rxc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyT-Ytkz0sMg",
        "outputId": "66838bca-eb10-426e-c67f-dac6727d2fff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complete Evidence Framework: r×c Contingency Tables\n",
            "==================================================\n",
            "Calculate p-fr-nb triplet for multinomial outcomes\n",
            "\n",
            "Number of rows (r): 3\n",
            "Number of columns (c): 2\n",
            "\n",
            "Enter all 6 cell counts (row by row):\n",
            "\n",
            "  Cell (1,1): 36\n",
            "  Cell (1,2): 6\n",
            "  Cell (2,1): 12\n",
            "  Cell (2,2): 31\n",
            "  Cell (3,1): 28\n",
            "  Cell (3,2): 14\n",
            "\n",
            "Input table:\n",
            "[[36  6]\n",
            " [12 31]\n",
            " [28 14]]\n",
            "\n",
            "Table dimensions: 3 × 2\n",
            "N_total = 127\n",
            "Test used: chi2\n",
            "Min expected count: 16.866142\n",
            "\n",
            "==================================================\n",
            "COMPLETE EVIDENCE ASSESSMENT (p-fr-nb)\n",
            "==================================================\n",
            "p = 0.000000\n",
            "fr (GFQ) = 0.078740\n",
            "nb (RQ) = 0.432513\n",
            "==================================================\n",
            "\n",
            "INTERPRETATION:\n",
            "Fragility: fragile\n",
            "Robustness: clear separation from independence\n",
            "\n",
            "GFI (raw count) = 10\n",
            "RRI (raw distance) = 27.464567\n",
            "Independent cells (k) = 2\n",
            "Note: GFI estimated (searched 50001 states). Calibrated estimate: 10 (range: 7-16, depth 7)\n",
            "\n",
            "Classification: SIGNIFICANT at α=0.05\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "# Complete Evidence Framework: r×c Contingency Tables (Independent Samples)\n",
        "# v.26-NOV-2025\n",
        "# Multinomial outcome analysis with complete p-fr-nb triplet\n",
        "#\n",
        "# Input:\n",
        "#   r×c contingency table (r rows, c columns)\n",
        "#   All cells as counts (non-negative integers)\n",
        "#\n",
        "# Output:\n",
        "#   p  = p-value from chi-square test (or Fisher's exact for 2×2 if small N)\n",
        "#   fr = GFQ (Global Fragility Quotient, stability of classification)\n",
        "#   nb = RQ (Risk Quotient, distance from independence)\n",
        "#\n",
        "# GFI Algorithm:\n",
        "#   Two-phase guaranteed optimal search:\n",
        "#   Phase 1: Exact BFS with unit steps (radius-limited, 2×2 only)\n",
        "#   Phase 2: Pure Dijkstra (h=0) with multi-resolution steps\n",
        "#   Falls back to RQ-calibrated estimate when search limit reached\n",
        "#\n",
        "# GFQ Formula:\n",
        "#   GFI = minimum number of cell-to-cell reallocations to flip significance\n",
        "#   GFQ = GFI / N  (normalized [0,1])\n",
        "#\n",
        "# RQ Formula:\n",
        "#   RRI = (1/k) Σ|O - E|  (raw distance from independence)\n",
        "#   RQ = RRI / (N/k)  (normalized [0,1])\n",
        "#   where k = (r-1)(c-1) = independent cells\n",
        "#         O = observed counts, E = expected under independence\n",
        "#\n",
        "# Test Selection:\n",
        "#   - 2×2 tables: Fisher's exact for small N/cells, else chi-square (no Yates)\n",
        "#   - r×c tables (r>2 or c>2): Chi-square only\n",
        "#\n",
        "# Interpretation:\n",
        "#   fr ∈ [0,1]: 0 = fragile, 1 = stable\n",
        "#   nb ∈ [0,1]: 0 = independent, 1 = maximally associated\n",
        "#\n",
        "# Limits:\n",
        "#   GFI computation: N ≤ 50000 (use RQ for larger samples)\n",
        "#   r×c tables (k>1): Significantly reduced limits due to exponential state space\n",
        "#\n",
        "# IF YOU USE THIS CALCULATOR PLEASE CITE:\n",
        "# Heston, T. F. (2025). Fragility Metrics Toolkit [Software]. Zenodo.\n",
        "#   https://doi.org/10.5281/zenodo.17254763\n",
        "#\n",
        "# © Thomas F. Heston 2025. CC-BY 4.0\n",
        "\n",
        "# ----- SciPy availability guard -----\n",
        "try:\n",
        "    import scipy\n",
        "except ImportError:\n",
        "    try:\n",
        "        import subprocess\n",
        "        import sys\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"scipy\"])\n",
        "        import scipy\n",
        "    except Exception:\n",
        "        print(\"Please install scipy: pip install scipy\")\n",
        "        raise\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import chi2_contingency, fisher_exact\n",
        "from collections import deque\n",
        "import heapq\n",
        "import sys\n",
        "\n",
        "# ========== CONFIGURABLE PARAMETERS ==========\n",
        "ALPHA = 0.05\n",
        "N_THRESHOLD = 5000         # Sample size threshold for chi-square vs Fisher (2×2 only)\n",
        "MIN_CELL_THRESHOLD = 50    # Minimum cell count for chi-square validity (2×2 only)\n",
        "GFI_THRESHOLD = 50000      # Don't compute GFI for N > this\n",
        "# =============================================\n",
        "\n",
        "# ---------- Core Utilities ----------\n",
        "\n",
        "def test_p(table, use_chi2=False):\n",
        "    \"\"\"\n",
        "    Unified significance test for r×c tables.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    table : 2D array-like\n",
        "        Contingency table\n",
        "    use_chi2 : bool\n",
        "        If True, use chi-square; if False, use Fisher (2×2 only)\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    float : p-value\n",
        "\n",
        "    Note:\n",
        "    -----\n",
        "    For 2×2 tables, uses Fisher's exact (two-sided) or chi-square WITHOUT Yates correction.\n",
        "    For r×c (r>2 or c>2), always uses chi-square.\n",
        "    Matches test selection in 2×2 independent binary module.\n",
        "    \"\"\"\n",
        "    table = np.array(table)\n",
        "    r, c = table.shape\n",
        "\n",
        "    if r == 2 and c == 2 and not use_chi2:\n",
        "        # Fisher's exact for 2×2\n",
        "        _, p = fisher_exact(table, alternative=\"two-sided\")\n",
        "        return p\n",
        "    else:\n",
        "        # Chi-square (no Yates correction to match 2×2 module)\n",
        "        _, p, _, _ = chi2_contingency(table, correction=False)\n",
        "        return p\n",
        "\n",
        "\n",
        "def is_significant(p, alpha=ALPHA):\n",
        "    \"\"\"Check if p-value indicates significance.\"\"\"\n",
        "    return p <= alpha\n",
        "\n",
        "\n",
        "def compute_expected(table):\n",
        "    \"\"\"Calculate expected counts under independence.\"\"\"\n",
        "    table = np.array(table, dtype=float)\n",
        "    N = table.sum()\n",
        "    if N == 0:\n",
        "        return table\n",
        "    row_totals = table.sum(axis=1, keepdims=True)\n",
        "    col_totals = table.sum(axis=0, keepdims=True)\n",
        "    return (row_totals @ col_totals) / N\n",
        "\n",
        "\n",
        "# ---------- RRI / RQ (Robustness) ----------\n",
        "\n",
        "def compute_rq(table):\n",
        "    \"\"\"\n",
        "    Calculate Risk Quotient (RQ) for r×c table.\n",
        "\n",
        "    RRI = (1/k) Σ|O - E|\n",
        "    RQ = RRI / (N/k)\n",
        "\n",
        "    where k = (r-1)(c-1) = independent cells\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    table : 2D array-like\n",
        "        Contingency table\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    dict : {'RRI': float, 'RQ': float, 'k': int}\n",
        "\n",
        "    Reference:\n",
        "    ----------\n",
        "    FRAGILITY_METRICS v9.7, §4.1\n",
        "\n",
        "    Note:\n",
        "    -----\n",
        "    Uses k = (r-1)(c-1) = independent cells, consistent with framework definition.\n",
        "    For 2×2: k = 1 (not 4).\n",
        "    \"\"\"\n",
        "    table = np.array(table, dtype=float)\n",
        "    r, c = table.shape\n",
        "    N = table.sum()\n",
        "\n",
        "    if N == 0:\n",
        "        return {'RRI': None, 'RQ': None, 'k': None}\n",
        "\n",
        "    # Expected counts under independence\n",
        "    expected = compute_expected(table)\n",
        "\n",
        "    # Number of independent cells\n",
        "    k = (r - 1) * (c - 1)\n",
        "\n",
        "    if k == 0:\n",
        "        return {'RRI': None, 'RQ': None, 'k': 0}\n",
        "\n",
        "    # RRI and RQ\n",
        "    RRI = np.abs(table - expected).sum() / k\n",
        "    RQ = RRI / (N / k)\n",
        "\n",
        "    return {\n",
        "        'RRI': float(RRI),\n",
        "        'RQ': float(RQ),\n",
        "        'k': int(k)\n",
        "    }\n",
        "\n",
        "\n",
        "# ---------- GFI / GFQ (Fragility) ----------\n",
        "\n",
        "def get_step_sizes(N):\n",
        "    \"\"\"Determine multi-resolution step sizes based on N.\"\"\"\n",
        "    if N < 1000:\n",
        "        return [1]\n",
        "    elif N < 5000:\n",
        "        return [1, 2, 3]\n",
        "    elif N < 20000:\n",
        "        return [1, 2, 3, 4]\n",
        "    else:\n",
        "        return [1, 2, 3, 4, 5]\n",
        "\n",
        "\n",
        "def table_to_state(table):\n",
        "    \"\"\"Convert table to state tuple (flattened, excluding last cell).\"\"\"\n",
        "    flat = table.flatten()\n",
        "    return tuple(flat[:-1])\n",
        "\n",
        "\n",
        "def state_to_table(state, N, shape):\n",
        "    \"\"\"Convert state back to table.\"\"\"\n",
        "    flat = list(state) + [N - sum(state)]\n",
        "    return np.array(flat).reshape(shape)\n",
        "\n",
        "\n",
        "def generate_neighbors_multistep(state, N, shape, step_sizes):\n",
        "    \"\"\"\n",
        "    Generate all neighbors with specified step sizes.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    state : tuple\n",
        "        Current state (flattened table excluding last cell)\n",
        "    N : int\n",
        "        Total sample size\n",
        "    shape : tuple\n",
        "        Table shape (r, c)\n",
        "    step_sizes : list\n",
        "        List of step sizes to use\n",
        "\n",
        "    Yields:\n",
        "    -------\n",
        "    tuple : (new_state, move, cost)\n",
        "        move = (src_idx, dst_idx, step)\n",
        "        cost = step\n",
        "    \"\"\"\n",
        "    tbl = state_to_table(state, N, shape)\n",
        "    flat = tbl.flatten()\n",
        "    n_cells = len(flat)\n",
        "\n",
        "    for step in step_sizes:\n",
        "        for src in range(n_cells):\n",
        "            if flat[src] < step:\n",
        "                continue\n",
        "            for dst in range(n_cells):\n",
        "                if dst == src:\n",
        "                    continue\n",
        "                new_flat = flat.copy()\n",
        "                new_flat[src] -= step\n",
        "                new_flat[dst] += step\n",
        "                new_state = tuple(new_flat[:-1])\n",
        "                yield new_state, (src, dst, step), step\n",
        "\n",
        "\n",
        "def estimate_gfi_from_search(max_depth_searched, states_explored, table, alpha=ALPHA):\n",
        "    \"\"\"\n",
        "    Estimate GFI using RQ correlation calibrated on actual search depth.\n",
        "\n",
        "    For contingency tables, empirical correlation: GFI ≈ c × sqrt(N × RQ × k)\n",
        "    Coefficient c calibrated using max_depth_searched as validation.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    max_depth_searched : int or None\n",
        "        Maximum depth reached before termination\n",
        "    states_explored : int\n",
        "        Total number of states explored\n",
        "    table : 2D array\n",
        "        Original contingency table\n",
        "    alpha : float\n",
        "        Significance level\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    tuple : (estimated_gfi, description_string)\n",
        "\n",
        "    Note:\n",
        "    -----\n",
        "    GFI measures STABILITY (resistance to significance flip).\n",
        "    High GFI = stable finding (hard to flip).\n",
        "    Low GFI = fragile finding (easy to flip).\n",
        "    This is different from RQ which measures distance from independence.\n",
        "    \"\"\"\n",
        "    N = table.sum()\n",
        "    r, c = table.shape\n",
        "    k = (r - 1) * (c - 1)\n",
        "\n",
        "    rq_result = compute_rq(table)\n",
        "    RQ = rq_result['RQ']\n",
        "\n",
        "    if RQ is None or RQ == 0:\n",
        "        if max_depth_searched and max_depth_searched > 0:\n",
        "            # Have search data but no RQ - use depth only\n",
        "            est = int(max_depth_searched * 1.5)\n",
        "            return est, f\"Search-based estimate: {est} (searched to depth {max_depth_searched})\"\n",
        "        return None, \"No estimate possible\"\n",
        "\n",
        "    # Base RQ formula: GFI ≈ c × sqrt(N × RQ × k)\n",
        "    # Coefficient c typically 0.6-1.0 for contingency tables\n",
        "    base_formula = np.sqrt(N * RQ * k)\n",
        "\n",
        "    if max_depth_searched is None or max_depth_searched == 0:\n",
        "        # No search - use middle coefficient\n",
        "        est = int(np.ceil(base_formula * 0.8))\n",
        "        lower = int(np.ceil(base_formula * 0.6))\n",
        "        upper = int(np.ceil(base_formula * 1.2))\n",
        "        return est, f\"RQ-based estimate: {est} (range: {lower}-{upper}, no search)\"\n",
        "\n",
        "    # Calibrate coefficient using search depth\n",
        "    # If search reached depth D, then c ≥ D / sqrt(N × RQ × k)\n",
        "    min_coefficient = max_depth_searched / base_formula if base_formula > 0 else 0.8\n",
        "\n",
        "    # Use calibrated coefficient, bounded reasonably\n",
        "    coefficient = max(0.6, min(min_coefficient * 1.3, 1.5))  # Allow 30% beyond proven minimum\n",
        "\n",
        "    estimated_gfi = int(np.ceil(base_formula * coefficient))\n",
        "\n",
        "    # Bounds\n",
        "    lower_bound = max_depth_searched\n",
        "    upper_bound = int(np.ceil(base_formula * 1.5))\n",
        "\n",
        "    # Clamp to bounds\n",
        "    estimated_gfi = max(lower_bound, min(estimated_gfi, upper_bound))\n",
        "\n",
        "    return estimated_gfi, f\"Calibrated estimate: {estimated_gfi} (range: {lower_bound}-{upper_bound}, depth {max_depth_searched})\"\n",
        "\n",
        "\n",
        "def compute_gfi_gfq(table, alpha=ALPHA, store_path=False):\n",
        "    \"\"\"\n",
        "    Calculate Global Fragility Index (GFI) and Quotient (GFQ) for r×c table.\n",
        "\n",
        "    Two-phase guaranteed optimal algorithm:\n",
        "    Phase 1: Exact BFS with unit steps (2×2 only, radius-limited)\n",
        "    Phase 2: Pure Dijkstra (h=0) with multi-resolution steps (guarantees optimality)\n",
        "\n",
        "    MATHEMATICAL GUARANTEES:\n",
        "    - When GFI is returned with \"optimal\" note: EXACT minimum-cost path\n",
        "    - When GFI is returned with \"estimate\" note: Calibrated based on search progress\n",
        "    - This is pure Dijkstra, NOT A* with heuristic\n",
        "    - h=0 is always admissible and guarantees correct result when search completes\n",
        "\n",
        "    Time complexity: O(N³ log N) worst case\n",
        "    Space complexity: O(N³) worst case\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    table : 2D array-like\n",
        "        Contingency table\n",
        "    alpha : float\n",
        "        Significance level\n",
        "    store_path : bool\n",
        "        If True, store witness path (memory intensive)\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    dict : Contains GFI, GFQ, baseline_p, final_p, test_used\n",
        "\n",
        "    Reference:\n",
        "    ----------\n",
        "    FRAGILITY_METRICS v9.7, §3.3\n",
        "    Algorithm ported from 2×2 independent binary module\n",
        "    \"\"\"\n",
        "    table = np.array(table, dtype=int)\n",
        "    r, c = table.shape\n",
        "\n",
        "    # Validate\n",
        "    if np.any(table < 0):\n",
        "        raise ValueError(\"All cells must be non-negative\")\n",
        "\n",
        "    N = table.sum()\n",
        "\n",
        "    if N == 0:\n",
        "        return {\n",
        "            \"GFI\": None, \"GFQ\": None,\n",
        "            \"baseline_p\": None, \"baseline_state\": None,\n",
        "            \"final_p\": None, \"witness_path\": [],\n",
        "            \"test_used\": None,\n",
        "            \"note\": \"Empty table.\"\n",
        "        }\n",
        "\n",
        "    # Calculate degrees of freedom\n",
        "    k = (r - 1) * (c - 1)\n",
        "\n",
        "    # Aggressive limits for r×c tables (k > 1) with large N\n",
        "    if k > 1 and N > 500:\n",
        "        # Determine test type for baseline p\n",
        "        if r == 2 and c == 2:\n",
        "            use_chi2 = (N > N_THRESHOLD) and (np.min(table) >= MIN_CELL_THRESHOLD)\n",
        "        else:\n",
        "            use_chi2 = True\n",
        "\n",
        "        base_p = test_p(table, use_chi2)\n",
        "        base_state_str = \"significant\" if is_significant(base_p, alpha) else \"non-significant\"\n",
        "\n",
        "        # Provide estimate based on RQ only (no search)\n",
        "        est_gfi, est_note = estimate_gfi_from_search(None, 0, table, alpha)\n",
        "\n",
        "        return {\n",
        "            \"GFI\": est_gfi,\n",
        "            \"GFQ\": est_gfi / N if est_gfi else None,\n",
        "            \"baseline_p\": base_p,\n",
        "            \"baseline_state\": base_state_str,\n",
        "            \"final_p\": None, \"witness_path\": [],\n",
        "            \"test_used\": \"chi2\" if use_chi2 else \"fisher_exact\",\n",
        "            \"note\": f\"GFI estimated for {r}×{c} table, N={N} (exponential state space). {est_note}\"\n",
        "        }\n",
        "\n",
        "    if N > GFI_THRESHOLD:\n",
        "        # Determine test type for baseline p\n",
        "        if r == 2 and c == 2:\n",
        "            use_chi2 = (N > N_THRESHOLD) and (np.min(table) >= MIN_CELL_THRESHOLD)\n",
        "        else:\n",
        "            use_chi2 = True\n",
        "\n",
        "        base_p = test_p(table, use_chi2)\n",
        "        base_state_str = \"significant\" if is_significant(base_p, alpha) else \"non-significant\"\n",
        "\n",
        "        # Provide estimate for large N\n",
        "        est_gfi, est_note = estimate_gfi_from_search(None, 0, table, alpha)\n",
        "\n",
        "        return {\n",
        "            \"GFI\": est_gfi,\n",
        "            \"GFQ\": est_gfi / N if est_gfi else None,\n",
        "            \"baseline_p\": base_p,\n",
        "            \"baseline_state\": base_state_str,\n",
        "            \"final_p\": None, \"witness_path\": [],\n",
        "            \"test_used\": \"chi2\" if use_chi2 else \"fisher_exact\",\n",
        "            \"note\": f\"GFI estimated for N > {GFI_THRESHOLD}. {est_note}\"\n",
        "        }\n",
        "\n",
        "    # Determine test type\n",
        "    if r == 2 and c == 2:\n",
        "        use_chi2 = (N > N_THRESHOLD) and (np.min(table) >= MIN_CELL_THRESHOLD)\n",
        "    else:\n",
        "        use_chi2 = True\n",
        "\n",
        "    # Create optimized test function to avoid repeated parameter passing\n",
        "    if use_chi2:\n",
        "        def test_func(tbl):\n",
        "            _, p, _, _ = chi2_contingency(tbl, correction=False)\n",
        "            return p\n",
        "    else:\n",
        "        def test_func(tbl):\n",
        "            _, p = fisher_exact(tbl, alternative=\"two-sided\")\n",
        "            return p\n",
        "\n",
        "    # Get baseline state\n",
        "    base_p = test_func(table)\n",
        "    base_state = is_significant(base_p, alpha)\n",
        "    target_state = not base_state\n",
        "\n",
        "    # Adaptive parameters based on N and k\n",
        "    if k == 1:  # 2×2 tables only\n",
        "        if N < 500:\n",
        "            PHASE1_RADIUS = 10\n",
        "        elif N < 5000:\n",
        "            PHASE1_RADIUS = 8\n",
        "        else:\n",
        "            PHASE1_RADIUS = 5\n",
        "    else:  # r×c tables with k > 1\n",
        "        PHASE1_RADIUS = 0  # Skip Phase 1 entirely\n",
        "\n",
        "    step_sizes = get_step_sizes(N)\n",
        "\n",
        "    # Dynamic max depth and state limits based on N and k\n",
        "    if k == 1:  # 2×2 tables\n",
        "        if N < 5000:\n",
        "            max_depth = 1000\n",
        "            MAX_STATES_EXPLORED = 100000\n",
        "        elif N < 20000:\n",
        "            max_depth = 500\n",
        "            MAX_STATES_EXPLORED = 50000\n",
        "        else:\n",
        "            max_depth = 200\n",
        "            MAX_STATES_EXPLORED = 20000\n",
        "    else:  # r×c tables (k > 1)\n",
        "        if N < 50:\n",
        "            max_depth = 500\n",
        "            MAX_STATES_EXPLORED = 100000\n",
        "        elif N < 150:\n",
        "            max_depth = 300\n",
        "            MAX_STATES_EXPLORED = 50000\n",
        "        elif N < 300:\n",
        "            max_depth = 200\n",
        "            MAX_STATES_EXPLORED = 20000\n",
        "        else:\n",
        "            max_depth = 150\n",
        "            MAX_STATES_EXPLORED = 10000\n",
        "\n",
        "    # ====================\n",
        "    # PHASE 1: Exact BFS with unit steps (2×2 only)\n",
        "    # ====================\n",
        "    start = table_to_state(table)\n",
        "    visited_phase1 = {start: 0}\n",
        "    queue_phase1 = deque([(start, 0, [] if store_path else None)])\n",
        "\n",
        "    phase1_result = None\n",
        "    states_explored_p1 = 0\n",
        "\n",
        "    if PHASE1_RADIUS > 0:  # Only run Phase 1 for 2×2 tables\n",
        "        while queue_phase1:\n",
        "            state, cost, path = queue_phase1.popleft()\n",
        "\n",
        "            # Early termination check at start\n",
        "            if cost > PHASE1_RADIUS:\n",
        "                break\n",
        "\n",
        "            states_explored_p1 += 1\n",
        "\n",
        "            # Test current state\n",
        "            tbl = state_to_table(state, N, table.shape)\n",
        "            p_now = test_func(tbl)\n",
        "\n",
        "            if is_significant(p_now, alpha) == target_state:\n",
        "                phase1_result = {\n",
        "                    \"GFI\": cost,\n",
        "                    \"GFQ\": cost / N if N else None,\n",
        "                    \"baseline_p\": base_p,\n",
        "                    \"baseline_state\": (\"significant\" if base_state else \"non-significant\"),\n",
        "                    \"final_p\": p_now,\n",
        "                    \"witness_path\": path if store_path else [],\n",
        "                    \"test_used\": \"chi2\" if use_chi2 else \"fisher_exact\",\n",
        "                    \"note\": f\"Phase 1 exact (explored {states_explored_p1} states)\"\n",
        "                }\n",
        "                break\n",
        "\n",
        "            # Generate unit-step neighbors only\n",
        "            for neighbor, move, neighbor_cost in generate_neighbors_multistep(state, N, table.shape, [1]):\n",
        "                new_cost = cost + neighbor_cost\n",
        "\n",
        "                if neighbor not in visited_phase1 or new_cost < visited_phase1[neighbor]:\n",
        "                    visited_phase1[neighbor] = new_cost\n",
        "                    new_path = (path + [move]) if store_path else None\n",
        "                    queue_phase1.append((neighbor, new_cost, new_path))\n",
        "\n",
        "    if phase1_result:\n",
        "        return phase1_result\n",
        "\n",
        "    # ========================\n",
        "    # PHASE 2: Pure Dijkstra (h=0)\n",
        "    # ========================\n",
        "\n",
        "    # Priority queue: (g_score, counter, state, path)\n",
        "    # NO HEURISTIC - pure Dijkstra with h=0\n",
        "    # Using h=0 guarantees optimality (any heuristic based on FI would overestimate)\n",
        "    counter = 0\n",
        "    g_scores = {start: 0}\n",
        "\n",
        "    pq = [(0, counter, start, [] if store_path else None)]  # f = g (no h)\n",
        "    visited_phase2 = set()\n",
        "    states_explored_p2 = 0\n",
        "    max_depth_reached = 0  # Track maximum depth actually explored\n",
        "\n",
        "    while pq:\n",
        "        g_score, _, state, path = heapq.heappop(pq)\n",
        "\n",
        "        if state in visited_phase2:\n",
        "            continue\n",
        "\n",
        "        visited_phase2.add(state)\n",
        "        states_explored_p2 += 1\n",
        "        max_depth_reached = max(max_depth_reached, g_score)\n",
        "\n",
        "        # Check state exploration limit\n",
        "        if states_explored_p2 > MAX_STATES_EXPLORED:\n",
        "            total_explored = states_explored_p1 + states_explored_p2\n",
        "\n",
        "            # Estimate based on actual search progress\n",
        "            est_gfi, est_note = estimate_gfi_from_search(max_depth_reached, total_explored, table, alpha)\n",
        "\n",
        "            return {\n",
        "                \"GFI\": est_gfi,\n",
        "                \"GFQ\": est_gfi / N if est_gfi else None,\n",
        "                \"baseline_p\": base_p,\n",
        "                \"baseline_state\": (\"significant\" if base_state else \"non-significant\"),\n",
        "                \"final_p\": base_p,\n",
        "                \"witness_path\": [],\n",
        "                \"test_used\": \"chi2\" if use_chi2 else \"fisher_exact\",\n",
        "                \"note\": f\"GFI estimated (searched {total_explored} states). {est_note}\"\n",
        "            }\n",
        "\n",
        "        # Check depth limit\n",
        "        if g_score > max_depth:\n",
        "            continue\n",
        "\n",
        "        # Test current state\n",
        "        tbl = state_to_table(state, N, table.shape)\n",
        "        p_now = test_func(tbl)\n",
        "\n",
        "        if is_significant(p_now, alpha) == target_state:\n",
        "            total_explored = states_explored_p1 + states_explored_p2\n",
        "            return {\n",
        "                \"GFI\": g_score,\n",
        "                \"GFQ\": g_score / N if N else None,\n",
        "                \"baseline_p\": base_p,\n",
        "                \"baseline_state\": (\"significant\" if base_state else \"non-significant\"),\n",
        "                \"final_p\": p_now,\n",
        "                \"witness_path\": path if store_path else [],\n",
        "                \"test_used\": \"chi2\" if use_chi2 else \"fisher_exact\",\n",
        "                \"note\": f\"Dijkstra optimal (explored {total_explored} states)\"\n",
        "            }\n",
        "\n",
        "        # Generate neighbors with multiple step sizes\n",
        "        for neighbor, move, move_cost in generate_neighbors_multistep(state, N, table.shape, step_sizes):\n",
        "            tentative_g = g_score + move_cost\n",
        "\n",
        "            # Only process if this is a better path\n",
        "            if neighbor not in g_scores or tentative_g < g_scores[neighbor]:\n",
        "                g_scores[neighbor] = tentative_g\n",
        "\n",
        "                # Pure Dijkstra: f = g (no heuristic)\n",
        "                f_score = tentative_g\n",
        "\n",
        "                counter += 1\n",
        "                new_path = (path + [move]) if store_path else None\n",
        "                heapq.heappush(pq, (f_score, counter, neighbor, new_path))\n",
        "\n",
        "    # Search exhausted - provide estimate based on actual search\n",
        "    total_explored = states_explored_p1 + states_explored_p2\n",
        "    est_gfi, est_note = estimate_gfi_from_search(max_depth_reached, total_explored, table, alpha)\n",
        "\n",
        "    return {\n",
        "        \"GFI\": est_gfi,\n",
        "        \"GFQ\": est_gfi / N if est_gfi else None,\n",
        "        \"baseline_p\": base_p,\n",
        "        \"baseline_state\": (\"significant\" if base_state else \"non-significant\"),\n",
        "        \"final_p\": base_p,\n",
        "        \"witness_path\": [],\n",
        "        \"test_used\": \"chi2\" if use_chi2 else \"fisher_exact\",\n",
        "        \"note\": f\"GFI estimated (searched {total_explored} states). {est_note}\"\n",
        "    }\n",
        "\n",
        "\n",
        "# ---------- Complete Evidence Calculator ----------\n",
        "\n",
        "def contingency_table_complete(table, alpha=ALPHA):\n",
        "    \"\"\"\n",
        "    Calculate complete p-fr-nb triplet for r×c contingency table.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    table : 2D array-like\n",
        "        Contingency table\n",
        "    alpha : float\n",
        "        Significance level\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    dict : Complete evidence assessment\n",
        "    \"\"\"\n",
        "    table = np.array(table, dtype=int)\n",
        "    r, c = table.shape\n",
        "    N = table.sum()\n",
        "\n",
        "    # Determine test type\n",
        "    if r == 2 and c == 2:\n",
        "        use_chi2 = (N > N_THRESHOLD) and (np.min(table) >= MIN_CELL_THRESHOLD)\n",
        "    else:\n",
        "        use_chi2 = True\n",
        "\n",
        "    # p-value\n",
        "    p_value = test_p(table, use_chi2)\n",
        "\n",
        "    # fr (GFQ)\n",
        "    if N <= GFI_THRESHOLD:\n",
        "        gfi_result = compute_gfi_gfq(table, alpha=alpha, store_path=False)\n",
        "        gfi = gfi_result.get(\"GFI\")\n",
        "        gfq = gfi_result.get(\"GFQ\")\n",
        "        gfi_note = gfi_result.get(\"note\", \"\")\n",
        "    else:\n",
        "        gfi = None\n",
        "        gfq = None\n",
        "        gfi_note = f\"GFI not computed for N > {GFI_THRESHOLD}\"\n",
        "\n",
        "    # nb (RQ)\n",
        "    rq_result = compute_rq(table)\n",
        "\n",
        "    # Expected counts for validation\n",
        "    expected = compute_expected(table)\n",
        "\n",
        "    return {\n",
        "        'p': p_value,\n",
        "        'fr': gfq,\n",
        "        'nb': rq_result['RQ'],\n",
        "        'GFI': gfi,\n",
        "        'RRI': rq_result['RRI'],\n",
        "        'k_independent': rq_result['k'],\n",
        "        'table_shape': (r, c),\n",
        "        'N_total': N,\n",
        "        'test_used': \"chi2\" if use_chi2 else \"fisher_exact\",\n",
        "        'expected_counts': expected,\n",
        "        'min_expected': np.min(expected),\n",
        "        'gfi_note': gfi_note\n",
        "    }\n",
        "\n",
        "\n",
        "# ---------- Interpretation Functions ----------\n",
        "\n",
        "def interpret_fragility(fr):\n",
        "    \"\"\"Interpret GFQ (fragility quotient).\"\"\"\n",
        "    if fr is None:\n",
        "        return \"not computed\"\n",
        "    if fr < 0.01:\n",
        "        return \"extremely fragile\"\n",
        "    elif fr < 0.05:\n",
        "        return \"very fragile\"\n",
        "    elif fr < 0.10:\n",
        "        return \"fragile\"\n",
        "    elif fr < 0.25:\n",
        "        return \"mildly stable\"\n",
        "    elif fr < 0.40:\n",
        "        return \"moderate stability\"\n",
        "    else:\n",
        "        return \"very stable\"\n",
        "\n",
        "\n",
        "def interpret_robustness(nb):\n",
        "    \"\"\"Interpret RQ (robustness).\"\"\"\n",
        "    if nb is None:\n",
        "        return \"not computed\"\n",
        "    if nb < 0.05:\n",
        "        return \"at independence (no association)\"\n",
        "    elif nb < 0.10:\n",
        "        return \"near independence (minimal association)\"\n",
        "    elif nb < 0.25:\n",
        "        return \"moderate distance from independence\"\n",
        "    elif nb < 0.50:\n",
        "        return \"clear separation from independence\"\n",
        "    else:\n",
        "        return \"far from independence (strong association)\"\n",
        "\n",
        "\n",
        "# ---------- Summary Interface ----------\n",
        "\n",
        "def contingency_summary(result):\n",
        "    \"\"\"Display complete p-fr-nb evidence assessment.\"\"\"\n",
        "    def fmt_f(x):\n",
        "        return \"NA\" if x is None or not np.isfinite(x) else f\"{x:.6f}\"\n",
        "\n",
        "    def fmt_i(x):\n",
        "        return \"NA\" if x is None else str(int(x))\n",
        "\n",
        "    r, c = result['table_shape']\n",
        "    print(f\"Table dimensions: {r} × {c}\")\n",
        "    print(f\"N_total = {fmt_i(result['N_total'])}\")\n",
        "    print(f\"Test used: {result['test_used']}\")\n",
        "    print(f\"Min expected count: {fmt_f(result['min_expected'])}\")\n",
        "\n",
        "    if result['min_expected'] < 5 and result['test_used'] == 'chi2':\n",
        "        print(\"⚠ Warning: Some expected counts < 5 (chi-square may be unreliable)\")\n",
        "    print()\n",
        "\n",
        "    # Complete evidence triplet\n",
        "    print(\"=\" * 50)\n",
        "    print(\"COMPLETE EVIDENCE ASSESSMENT (p-fr-nb)\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"p = {fmt_f(result['p'])}\")\n",
        "    print(f\"fr (GFQ) = {fmt_f(result['fr'])}\")\n",
        "    print(f\"nb (RQ) = {fmt_f(result['nb'])}\")\n",
        "    print(\"=\" * 50)\n",
        "    print()\n",
        "\n",
        "    # Interpretations\n",
        "    interp_fr = interpret_fragility(result['fr'])\n",
        "    interp_nb = interpret_robustness(result['nb'])\n",
        "\n",
        "    print(\"INTERPRETATION:\")\n",
        "    print(f\"Fragility: {interp_fr}\")\n",
        "    print(f\"Robustness: {interp_nb}\")\n",
        "    print()\n",
        "\n",
        "    # Additional metrics\n",
        "    print(f\"GFI (raw count) = {fmt_i(result['GFI'])}\")\n",
        "    print(f\"RRI (raw distance) = {fmt_f(result['RRI'])}\")\n",
        "    print(f\"Independent cells (k) = {fmt_i(result['k_independent'])}\")\n",
        "\n",
        "    if result['gfi_note']:\n",
        "        print(f\"Note: {result['gfi_note']}\")\n",
        "\n",
        "    # Significance classification\n",
        "    is_sig = result['p'] <= ALPHA\n",
        "    print()\n",
        "    print(f\"Classification: {'SIGNIFICANT' if is_sig else 'NON-SIGNIFICANT'} at α={ALPHA}\")\n",
        "\n",
        "\n",
        "# ---------- CLI Entry Point ----------\n",
        "\n",
        "def main():\n",
        "    print(\"Complete Evidence Framework: r×c Contingency Tables\")\n",
        "    print(\"=\" * 50)\n",
        "    print(\"Calculate p-fr-nb triplet for multinomial outcomes\")\n",
        "    print()\n",
        "\n",
        "    # Get table dimensions\n",
        "    r = int(input(\"Number of rows (r): \").strip())\n",
        "    c = int(input(\"Number of columns (c): \").strip())\n",
        "\n",
        "    if r < 2 or c < 2:\n",
        "        print(\"Error: Need at least 2×2 table\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    print()\n",
        "    print(f\"Enter all {r*c} cell counts (row by row):\")\n",
        "    print()\n",
        "\n",
        "    # Get cell values\n",
        "    table = []\n",
        "    for i in range(r):\n",
        "        row = []\n",
        "        for j in range(c):\n",
        "            val = int(input(f\"  Cell ({i+1},{j+1}): \").strip())\n",
        "            if val < 0:\n",
        "                print(\"Error: Cell counts must be non-negative\")\n",
        "                sys.exit(1)\n",
        "            row.append(val)\n",
        "        table.append(row)\n",
        "\n",
        "    print()\n",
        "    print(\"Input table:\")\n",
        "    table_array = np.array(table)\n",
        "    print(table_array)\n",
        "    print()\n",
        "\n",
        "    # Calculate complete evidence\n",
        "    result = contingency_table_complete(table, alpha=ALPHA)\n",
        "    contingency_summary(result)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mTGFJOe80vrk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}