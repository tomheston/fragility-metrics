{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMFFmo0FftXRJYKqq3xeal",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomheston/fragility-metrics/blob/main/notebooks/diagnostic_2x2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "F2kSM9w6N60r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81c81261-4e32-4ce5-d44b-c77af04f219f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diagnostic 2x2 Calculator – v9.5 compliant\n",
            "\n",
            "TP: 15\n",
            "FN: 5\n",
            "FP: 3\n",
            "TN: 8\n",
            "\n",
            "Metric: 1=sensitivity 2=specificity 3=ppv 4=npv 5=accuracy\n",
            "Choose (1-5) [default 5]: 1\n",
            "Benchmark p₀ [default 0.50]: 0.7\n",
            "\n",
            "Claim:\n",
            "1. Metric ≥ p₀ (at or above benchmark)\n",
            "2. Metric ≤ p₀ (at or below benchmark)\n",
            "Enter 1 or 2 [default 1]: 1\n",
            "\n",
            "================ p–fr–nb ================\n",
            "Displayed p-value = 0.416371\n",
            "DFI = 5\n",
            "DFQ = 0.250000\n",
            "DNB = 0.704687\n",
            "=========================================\n",
            "\n",
            "Interpretation:\n",
            "Diagnostic 2×2: TP=15, FN=5, FP=3, TN=8\n",
            "Metric: SENSITIVITY  (benchmark p₀ = 0.7)\n",
            "Observed = 0.7500 (15/20)\n",
            "Claim '≥ p₀' is NOT rejected (α = 0.05)\n",
            "Displayed p-value = 0.416371\n",
            "DFI = 5: toggling 5 event(s) would reject the claim.\n",
            "DFQ = 0.250000 → very stable\n",
            "DNB = 0.704687 → diagnostic is far from neutrality\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "# Fragility Metrics Toolkit: Diagnostic Metrics (Benchmark Framework)\n",
        "# 20-NOV-2025\n",
        "# Fully aligned with FRAGILITY_METRICS.md v9.5 §3.4 DFQ and §4 DNB\n",
        "#\n",
        "# Input: TP, FN, FP, TN + chosen metric + benchmark p₀ + claim direction\n",
        "# Output: p (display p-value), fr (DFI/DFQ), nb (DNB)\n",
        "#\n",
        "# Logic identical to the released proportion_vs_benchmark.ipynb\n",
        "#\n",
        "# IF YOU USE THIS CALCULATOR PLEASE CITE:\n",
        "# Heston, T. F. (2025). Fragility Metrics Toolkit [Software]. Zenodo. https://doi.org/10.5281/zenodo.17254763\n",
        "#\n",
        "# © Thomas F. Heston 2025. CC-BY 4.0\n",
        "\n",
        "try:\n",
        "    from scipy.stats import binomtest\n",
        "    from math import log, sqrt\n",
        "    import numpy as np\n",
        "except ImportError:\n",
        "    import subprocess, sys\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"scipy\"])\n",
        "    from scipy.stats import binomtest\n",
        "    from math import log, sqrt\n",
        "    import numpy as np\n",
        "\n",
        "ALPHA = 0.05\n",
        "\n",
        "# ---------- DNB (v9.5 exact, with documented Haldane–Anscombe 0.5 correction) ----------\n",
        "def compute_dnb(tp, fn, fp, tn):\n",
        "    a, b, c, d = tp + 0.5, fn + 0.5, fp + 0.5, tn + 0.5\n",
        "    dor = (a * d) / (b * c)\n",
        "    se = sqrt(1/a + 1/b + 1/c + 1/d)\n",
        "    ln_dor = abs(log(dor))\n",
        "    return 0.0 if ln_dor == 0 else ln_dor / (ln_dor + se)\n",
        "\n",
        "# ---------- Metric → (k, n_relevant) ----------\n",
        "def get_diagnostic_params(tp, fn, fp, tn, metric):\n",
        "    metric = metric.lower()\n",
        "    if metric == \"sensitivity\":\n",
        "        return tp, tp + fn\n",
        "    elif metric == \"specificity\":\n",
        "        return tn, fp + tn\n",
        "    elif metric == \"ppv\":\n",
        "        return tp, tp + fp\n",
        "    elif metric == \"npv\":\n",
        "        return tn, fn + tn\n",
        "    elif metric == \"accuracy\":\n",
        "        return tp + tn, tp + fn + fp + tn\n",
        "    else:\n",
        "        raise ValueError(\"metric must be sensitivity, specificity, ppv, npv, or accuracy\")\n",
        "\n",
        "# ---------- Core BFI/BFQ logic (identical to proportion_vs_benchmark.ipynb) ----------\n",
        "def compute_dfi_dfq(k: int, n: int, p0: float, alternative: str = \"greater\", alpha: float = ALPHA):\n",
        "    opp_alt = \"less\" if alternative == \"greater\" else \"greater\"\n",
        "    opposite_proven = binomtest(k, n, p0, alternative=opp_alt).pvalue <= alpha\n",
        "\n",
        "    if alternative == \"greater\":                                 # Claim: ≥ p0\n",
        "        if opposite_proven:                                      # Already proven below → increase k until not\n",
        "            for d in range(1, n - k + 1):\n",
        "                if binomtest(k + d, n, p0, alternative=\"less\").pvalue > alpha:\n",
        "                    return d, d / n\n",
        "            return None, None\n",
        "        else:                                                    # Supported → decrease k until proven below\n",
        "            for d in range(1, k + 1):\n",
        "                if binomtest(k - d, n, p0, alternative=\"less\").pvalue <= alpha:\n",
        "                    return d, d / n\n",
        "            return None, None\n",
        "    else:                                                        # Claim: ≤ p0\n",
        "        if opposite_proven:                                      # Already proven above → decrease k until not\n",
        "            for d in range(1, k + 1):\n",
        "                if binomtest(k - d, n, p0, alternative=\"greater\").pvalue > alpha:\n",
        "                    return d, d / n\n",
        "            return None, None\n",
        "        else:                                                    # Supported → increase k until proven above\n",
        "            for d in range(1, n - k + 1):\n",
        "                if binomtest(k + d, n, p0, alternative=\"greater\").pvalue <= alpha:\n",
        "                    return d, d / n\n",
        "            return None, None\n",
        "\n",
        "# ---------- Display p-value (context-aware, same as proportion_vs_benchmark) ----------\n",
        "def display_pvalue(k, n, p0, alternative):\n",
        "    if alternative == \"greater\":\n",
        "        return binomtest(k, n, p0, alternative=\"greater\").pvalue\n",
        "    else:\n",
        "        phat = k / n\n",
        "        if phat > p0:\n",
        "            return binomtest(k, n, p0, alternative=\"greater\").pvalue\n",
        "        else:\n",
        "            return binomtest(k, n, p0, alternative=\"less\").pvalue\n",
        "\n",
        "# ---------- High-level ----------\n",
        "def diagnostic_2x2(tp: int, fn: int, fp: int, tn: int,\n",
        "                   metric: str = \"accuracy\",\n",
        "                   p0: float = 0.50,\n",
        "                   alternative: str = \"greater\"):\n",
        "    k, n_rel = get_diagnostic_params(tp, fn, fp, tn, metric)\n",
        "    if n_rel == 0:\n",
        "        raise ValueError(f\"{metric.capitalize()} undefined (denominator = 0)\")\n",
        "\n",
        "    p_disp = display_pvalue(k, n_rel, p0, alternative)\n",
        "    dfi, dfq = compute_dfi_dfq(k, n_rel, p0, alternative, ALPHA)\n",
        "    dnb = compute_dnb(tp, fn, fp, tn)\n",
        "\n",
        "    return {\n",
        "        \"metric\": metric,\n",
        "        \"p0\": p0,\n",
        "        \"alternative\": alternative,\n",
        "        \"k\": k,\n",
        "        \"n_relevant\": n_rel,\n",
        "        \"observed\": k / n_rel,\n",
        "        \"p_display\": p_disp,\n",
        "        \"fr\": {\"DFI\": dfi, \"DFQ\": dfq},\n",
        "        \"nb\": {\"DNB\": dnb}\n",
        "    }\n",
        "\n",
        "# ---------- Narrative (aligned with proportion_vs_benchmark) ----------\n",
        "def generate_narrative(res, tp, fn, fp, tn):\n",
        "    claim_text = \"at or above\" if res[\"alternative\"] == \"greater\" else \"at or below\"\n",
        "    opp_alt = \"less\" if res[\"alternative\"] == \"greater\" else \"greater\"\n",
        "    opposite_proven = binomtest(res[\"k\"], res[\"n_relevant\"], res[\"p0\"], alternative=opp_alt).pvalue <= ALPHA\n",
        "\n",
        "    claim_state = \"rejected\" if opposite_proven else \"NOT rejected\"\n",
        "\n",
        "    lines = [\n",
        "        f\"Diagnostic 2×2: TP={tp}, FN={fn}, FP={fp}, TN={tn}\",\n",
        "        f\"Metric: {res['metric'].upper()}  (benchmark p₀ = {res['p0']})\",\n",
        "        f\"Observed = {res['observed']:.4f} ({res['k']}/{res['n_relevant']})\",\n",
        "        f\"Claim '≥ p₀' is {claim_state} (α = 0.05)\" if res[\"alternative\"] == \"greater\"\n",
        "        else f\"Claim '≤ p₀' is {claim_state} (α = 0.05)\",\n",
        "        f\"Displayed p-value = {res['p_display']:.6f}\",\n",
        "    ]\n",
        "\n",
        "    if res[\"fr\"][\"DFI\"] is not None:\n",
        "        if opposite_proven:\n",
        "            frag_txt = f\"DFI = {res['fr']['DFI']}: toggling {res['fr']['DFI']} event(s) means the claim can no longer be rejected.\"\n",
        "        else:\n",
        "            frag_txt = f\"DFI = {res['fr']['DFI']}: toggling {res['fr']['DFI']} event(s) would reject the claim.\"\n",
        "\n",
        "        stability = (\"extremely fragile\" if res['fr']['DFQ'] < 0.01 else\n",
        "                     \"very fragile\" if res['fr']['DFQ'] < 0.05 else\n",
        "                     \"fragile\" if res['fr']['DFQ'] < 0.10 else\n",
        "                     \"moderately stable\" if res['fr']['DFQ'] < 0.25 else\n",
        "                     \"very stable\")\n",
        "        lines += [frag_txt, f\"DFQ = {res['fr']['DFQ']:.6f} → {stability}\"]\n",
        "    else:\n",
        "        lines.append(\"DFQ = 1.000000 (maximally stable)\")\n",
        "\n",
        "    sep = (\"at neutrality boundary\" if res['nb']['DNB'] < 0.05 else\n",
        "           \"near neutrality\" if res['nb']['DNB'] < 0.10 else\n",
        "           \"moderately separated\" if res['nb']['DNB'] < 0.25 else\n",
        "           \"clearly separated\" if res['nb']['DNB'] < 0.50 else\n",
        "           \"far from neutrality\")\n",
        "    lines.append(f\"DNB = {res['nb']['DNB']:.6f} → diagnostic is {sep}\")\n",
        "\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "# ---------- CLI ----------\n",
        "def main():\n",
        "    print(\"Diagnostic 2x2 Calculator – v9.5 compliant\\n\")\n",
        "    tp = int(input(\"TP: \").strip())\n",
        "    fn = int(input(\"FN: \").strip())\n",
        "    fp = int(input(\"FP: \").strip())\n",
        "    tn = int(input(\"TN: \").strip())\n",
        "\n",
        "    print(\"\\nMetric: 1=sensitivity 2=specificity 3=ppv 4=npv 5=accuracy\")\n",
        "    mchoice = input(\"Choose (1-5) [default 5]: \").strip() or \"5\"\n",
        "    metrics = {\"1\": \"sensitivity\", \"2\": \"specificity\", \"3\": \"ppv\", \"4\": \"npv\", \"5\": \"accuracy\"}\n",
        "    metric = metrics[mchoice]\n",
        "\n",
        "    p0 = float(input(f\"Benchmark p₀ [default 0.50]: \").strip() or \"0.50\")\n",
        "\n",
        "    print(\"\\nClaim:\")\n",
        "    print(\"1. Metric ≥ p₀ (at or above benchmark)\")\n",
        "    print(\"2. Metric ≤ p₀ (at or below benchmark)\")\n",
        "    choice = input(\"Enter 1 or 2 [default 1]: \").strip() or \"1\"\n",
        "    alternative = \"greater\" if choice == \"1\" else \"less\"\n",
        "\n",
        "    res = diagnostic_2x2(tp, fn, fp, tn, metric, p0, alternative)\n",
        "\n",
        "    print(\"\\n================ p–fr–nb ================\")\n",
        "    print(f\"Displayed p-value = {res['p_display']:.6f}\")\n",
        "    print(f\"DFI = {res['fr']['DFI']}\")\n",
        "    print(f\"DFQ = {1.0 if res['fr']['DFQ'] is None else res['fr']['DFQ']:.6f}\")\n",
        "    print(f\"DNB = {res['nb']['DNB']:.6f}\")\n",
        "    print(\"=========================================\\n\")\n",
        "\n",
        "    print(\"Interpretation:\")\n",
        "    print(generate_narrative(res, tp, fn, fp, tn))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}